{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_sentences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from spacy.lang.en import English\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions defining synthesis sentence predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom transformer using spaCy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic utility function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "\n",
    "#Create spacy tokenizer that parses a sentence and generates tokens\n",
    "#these can also be replaced by word vectors \n",
    "def spacy_tokenizer(sentence):\n",
    "    punctuations = string.punctuation\n",
    "    parser = English()\n",
    "    tokens = parser(sentence)\n",
    "    tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "    tokens = [tok for tok in tokens if (tok not in stopwords and tok not in punctuations)]     \n",
    "    return tokens\n",
    "\n",
    "def syn_sen_predictor(X_train, Y_train):\n",
    "    #create vectorizer object to generate feature vectors, we will use custom spacy’s tokenizer\n",
    "    vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "    classifier = LinearSVC()\n",
    "\n",
    "    # Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "    pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                     ('vectorizer', vectorizer),\n",
    "                     ('classifier', classifier)])\n",
    "\n",
    "    # Fit model using training data\n",
    "    pipe.fit([X_train[i] for i in range(len(X_train))], [Y_train[i] for i in range(len(Y_train))])\n",
    "\n",
    "    return pipe\n",
    "\n",
    "def classify_sentences(model, X_sentences):\n",
    "    \n",
    "    pred_data = model.predict(X_sentences) \n",
    "    predicted_output = pred_data.astype(np.float)\n",
    "    synthesis_sentence = []\n",
    "    not_synthesis_sentence = []\n",
    "    for i in range(len(predicted_output)):\n",
    "        if predicted_output[i] == 1:\n",
    "            synthesis_sentence.append(X_sentences[i])\n",
    "        else:\n",
    "            not_synthesis_sentence.append(X_sentences[i])\n",
    "            \n",
    "    return synthesis_sentence, not_synthesis_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation for training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "#manually identified/tagged synthesis paragraphs\n",
    "train_p = [[117, 118, 119], [112], [117], [122, 125], [88]]\n",
    "p=[1,2,3,4,5]\n",
    "syn_yes=[]\n",
    "syn_no=[]\n",
    "for i in range(len(p)):\n",
    "    sen_yes_arr, sen_no_arr = extract_sentences.extract_sentences('journal_articles/Paper' + str(p[i]) + '.html', train_p[p[i]-1])\n",
    "    for j in range(len(sen_yes_arr)):\n",
    "        syn_yes.append(sen_yes_arr[j])\n",
    "    for k in range(len(sen_no_arr)):\n",
    "        syn_no.append(sen_no_arr[k])\n",
    "Syn_sen=pd.DataFrame({'x':syn_yes, 'y':np.ones(len(syn_yes))})\n",
    "Syn_not_sen=pd.DataFrame({'x':syn_no, 'y':np.zeros(len(syn_no))})\n",
    "Train=[Syn_sen,Syn_not_sen]\n",
    "train_data=pd.concat(Train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[0]\n",
    "test_p = [[109]]\n",
    "syn_test_yes=[]\n",
    "syn_test_no=[]\n",
    "for i in range(len(t)):\n",
    "    sen_yes_arr, sen_no_arr = extract_sentences.extract_sentences('journal_articles/Paper' + str(t[i]) + '.html', test_p[t[i]])\n",
    "    for j in range(len(sen_yes_arr)):\n",
    "        syn_test_yes.append(sen_yes_arr[j])\n",
    "    for k in range(len(sen_no_arr)):\n",
    "        syn_test_no.append(sen_no_arr[k])\n",
    "Syn_test_sen=pd.DataFrame({'X':syn_test_yes, 'Y':np.ones(len(syn_test_yes))})\n",
    "Syn_test_not_sen=pd.DataFrame({'X':syn_test_no, 'Y':np.zeros(len(syn_test_no))})\n",
    "Test=[Syn_test_sen,Syn_test_not_sen]\n",
    "test_data=pd.concat(Test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[str(train_data['x'][x]) for x in range(train_data.shape[0])]\n",
    "Y_train=[str(train_data['y'][x]) for x in range(train_data.shape[0])]\n",
    "X_test=[str(test_data['X'][x]) for x in range(test_data.shape[0])]\n",
    "Y_test=[str(test_data['Y'][x]) for x in range(test_data.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_sen_model = syn_sen_predictor(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model and measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9894242068155111\n"
     ]
    }
   ],
   "source": [
    "pred_data = syn_sen_model.predict(X_test) \n",
    "print (\"Accuracy:\", accuracy_score(Y_test, pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesis_sentences, not_synthesis_sentences = classify_sentences(syn_sen_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A 200–300-nm-thick mesoporous TiO2 (particle size: about 50 nm, crystalline phase: anatase) film was spin-coated onto the bl-TiO2/FTO substrate using home-made pastes14 and calcining at 500 °C for 1 h in air to remove organic components.',\n",
       " 'CH3NH3I (MAI) and CH3NH3Br (MABr) were first synthesized by reacting 27.86 ml CH3NH2 (40% in methanol, Junsei Chemical) and 30 ml HI (57 wt% in water, Aldrich) or 44 ml HBr (48 wt% in water, Aldrich) in a 250 ml round-bottom flask at 0 °C for 4 h with stirring, respectively.',\n",
       " 'The precipitate was recovered by evaporation at 55 °C for 1 h. MAI and MABr were dissolved in ethanol, recrystallized from diethyl ether, and dried at 60 °C in a vacuum oven for 24 h.',\n",
       " 'The resulting solution was coated onto the mp-TiO2/bl-TiO2/FTO substrate by a consecutive two-step spin-coating process at 1,000 and 5,000 r.p.m for 10 and 20 s, respectively.',\n",
       " 'During the second spin-coating step, the substrate (around 1 cm × 1 cm) was treated with toluene drop-casting.',\n",
       " 'The substrate was dried on a hot plate at 100 °C for 10 min.',\n",
       " 'Furthermore, it was reported that the uniformity of the perovskite films depended on the thickness of the TiO2 compact layer, and modification of the spinning conditions could not achieve 100% surface coverage20.',\n",
       " 'We see that the formation of the perovskite phase is accompanied by the complete transformation of the MAI–PbI2–DMSO at 130 °C, whereas both MAI–PbI2–DMSO and perovskite phases coexist at 100 °C.',\n",
       " 'As shown in Fig.\\xa02d, at the initial stage during spinning, the film is composed of MAI and PbI2 dissolved in the DMSO/GBL solvent mixture, whereas in the intermediate stage, the composition of the film is concentrated by the evaporation of GBL.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesis_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chemdataextractor\n",
    "from chemdataextractor import Document\n",
    "from chemdataextractor.reader import HtmlReader\n",
    "\n",
    "def extract_all_sentences(paper_path):\n",
    "    \"\"\"extracts all sentences in paper as a list of strings\"\"\"\n",
    "\n",
    "    f = open(paper_path, 'rb')\n",
    "    doc = Document.from_file(f, readers=[HtmlReader()])\n",
    "    \n",
    "    sentences_list = list()\n",
    "\n",
    "    for i in range(len(doc.elements)):\n",
    "        if type(doc.elements[i]) == chemdataextractor.doc.text.Paragraph:\n",
    "            for sentence in doc.elements[i]:\n",
    "                sentences_list.append(str(sentence))\n",
    "\n",
    "    return sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Furthermore, it was reported that the uniformity of the perovskite films depended on the thickness of the TiO2 compact layer, and modification of the spinning conditions could not achieve 100% surface coverage20.',\n",
       " 'We see that the formation of the perovskite phase is accompanied by the complete transformation of the MAI–PbI2–DMSO at 130 °C, whereas both MAI–PbI2–DMSO and perovskite phases coexist at 100 °C.',\n",
       " 'As shown in Fig.\\xa02d, at the initial stage during spinning, the film is composed of MAI and PbI2 dissolved in the DMSO/GBL solvent mixture, whereas in the intermediate stage, the composition of the film is concentrated by the evaporation of GBL.',\n",
       " 'A 200–300-nm-thick mesoporous TiO2 (particle size: about 50 nm, crystalline phase: anatase) film was spin-coated onto the bl-TiO2/FTO substrate using home-made pastes14 and calcining at 500 °C for 1 h in air to remove organic components.',\n",
       " 'CH3NH3I (MAI) and CH3NH3Br (MABr) were first synthesized by reacting 27.86 ml CH3NH2 (40% in methanol, Junsei Chemical) and 30 ml HI (57 wt% in water, Aldrich) or 44 ml HBr (48 wt% in water, Aldrich) in a 250 ml round-bottom flask at 0 °C for 4 h with stirring, respectively.',\n",
       " 'The precipitate was recovered by evaporation at 55 °C for 1 h. MAI and MABr were dissolved in ethanol, recrystallized from diethyl ether, and dried at 60 °C in a vacuum oven for 24 h.',\n",
       " 'The resulting solution was coated onto the mp-TiO2/bl-TiO2/FTO substrate by a consecutive two-step spin-coating process at 1,000 and 5,000 r.p.m for 10 and 20 s, respectively.',\n",
       " 'During the second spin-coating step, the substrate (around 1 cm × 1 cm) was treated with toluene drop-casting.',\n",
       " 'The substrate was dried on a hot plate at 100 °C for 10 min.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sentences = extract_all_sentences('journal_articles/Paper0.html')\n",
    "synthesis_sentences, not_synthesis_sentences = classify_sentences(syn_sen_model, X_sentences)\n",
    "synthesis_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
